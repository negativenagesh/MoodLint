{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd4bc55-8e47-44c0-874d-28b080ee2fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mtcnn in /home/lab-08/.local/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.4.2 in /home/lab-08/.local/lib/python3.12/site-packages (from mtcnn) (1.4.2)\n",
      "Requirement already satisfied: lz4>=4.3.3 in /home/lab-08/.local/lib/python3.12/site-packages (from mtcnn) (4.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install mtcnn --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f644f3db-b840-4ee2-8203-b01cc31f42e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/lab-08/.local/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/lab-08/.local/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a86a021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   2%|▎                    | 157/9111 [00:27<21:58,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.505919.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   5%|█                    | 488/9111 [01:32<17:36,  8.16it/s]2025-04-24 12:00:01.646132: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,24,24,3] vs. [1,1,1,28]\n",
      "Processing Images:   5%|█▏                   | 490/9111 [01:32<16:36,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.506135.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   6%|█▎                   | 592/9111 [01:55<46:22,  3.06it/s]2025-04-24 12:00:24.543440: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:   7%|█▎                   | 593/9111 [01:55<43:03,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.398594.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   7%|█▍                   | 622/9111 [02:01<26:12,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.505766.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  13%|██▌                 | 1163/9111 [04:08<19:05,  6.94it/s]2025-04-24 12:02:37.646840: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:  13%|██▌                 | 1165/9111 [04:08<17:41,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.505762.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  16%|███▏                | 1473/9111 [05:28<33:28,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.568954.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  18%|███▌                | 1637/9111 [06:03<19:15,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.506097.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  20%|███▉                | 1779/9111 [06:40<29:21,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0d50640513cbafb7750e89b5da3937bd4bbb4881df6911d88e2b6cb0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  20%|███▉                | 1808/9111 [06:47<19:50,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.569844.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  23%|████▌               | 2050/9111 [07:48<31:50,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in ffhq_2754.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  26%|█████▏              | 2365/9111 [09:05<18:35,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.568286.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  28%|█████▋              | 2572/9111 [09:39<13:23,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.569571.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  29%|█████▊              | 2662/9111 [09:55<09:17, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0c0bbcbcf39bd2fa6adf6c99c6cea4bea652d554f0324dcae6b98d2e.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  34%|██████▋             | 3056/9111 [11:30<30:57,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0df74f106734e3930bbcff6c523b3e688b4437f4d13f91d53ad16d6f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  35%|██████▉             | 3152/9111 [11:54<31:56,  3.11it/s]2025-04-24 12:10:23.555904: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:  35%|██████▉             | 3154/9111 [11:54<22:30,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.506066.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  39%|███████▊            | 3554/9111 [13:16<16:08,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0ca8f4b47b8675b80ec2aea217fcd8055f1178aa6b71b4d512ea0551.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  41%|████████▎           | 3779/9111 [14:04<24:45,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.398565.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  46%|█████████▏          | 4194/9111 [15:35<14:41,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.506019.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  47%|█████████▍          | 4296/9111 [16:00<17:42,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.505985.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  48%|█████████▋          | 4397/9111 [16:22<27:56,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0a60f0ad428ff59cb55725695631d529769dd36e279135f3597f45ec.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  52%|██████████▍         | 4734/9111 [17:44<13:57,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.506144.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  52%|██████████▍         | 4748/9111 [17:48<18:57,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0dbd9c2a24de16493f9dcf2ab3463e24e23528c8650e2f093261d968.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  53%|██████████▌         | 4803/9111 [18:00<12:31,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0e3d8e9bdef79317099867d2f0dc7b3d8c88e9e3605329ff217bdda8.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  56%|███████████         | 5063/9111 [18:56<14:42,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.505810.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  56%|███████████▏        | 5088/9111 [19:02<14:23,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.569293.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  56%|███████████▏        | 5094/9111 [19:03<15:51,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.568512.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  60%|███████████▉        | 5443/9111 [20:20<12:03,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0ab02465f84c80960ac43421a0c0777becae999a35351025af3541fd.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  63%|████████████▌       | 5746/9111 [21:30<10:57,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in ffhq_1834.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  65%|████████████▉       | 5915/9111 [22:07<07:50,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.568292.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  66%|█████████████▏      | 6019/9111 [22:28<11:43,  4.40it/s]2025-04-24 12:20:57.821690: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:  66%|█████████████▏      | 6020/9111 [22:28<12:45,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.272034.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  72%|██████████████▍     | 6577/9111 [24:28<09:05,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.271925.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  73%|██████████████▋     | 6693/9111 [24:51<05:29,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0d1a1ad8a5d5f18c09aa10fe5159289700bda27a71898b6a94e9ad10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  78%|███████████████▌    | 7104/9111 [26:11<04:26,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.505768.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  78%|███████████████▋    | 7126/9111 [26:15<08:25,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.272035.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  84%|████████████████▉   | 7690/9111 [28:17<05:53,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in ffhq_2544.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  86%|█████████████████▏  | 7815/9111 [28:43<03:14,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.505964.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  86%|█████████████████▏  | 7836/9111 [28:47<03:16,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in ffhq_2604.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  89%|█████████████████▋  | 8078/9111 [29:38<03:57,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.505906.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  90%|██████████████████  | 8235/9111 [30:11<02:55,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0dc5ffea95a91c35106321431e9651b26f6b72777c48b3c3138a4df0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  93%|██████████████████▌ | 8480/9111 [30:51<02:41,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0de53cc1b3ab9cc10fe2bb0dfa0e4f5eb4b21541e0e35d872ff93c0d.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  94%|██████████████████▊ | 8563/9111 [31:00<01:11,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.569197.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  95%|██████████████████▉ | 8616/9111 [31:07<00:45, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.505787.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  95%|███████████████████ | 8697/9111 [31:18<00:43,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0b4d411c4c553d47d5f4a4dbf4404d32c7308c8dd5ca0a0f81df5803.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  97%|███████████████████▎| 8802/9111 [31:30<00:38,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.505782.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|████████████████████| 9111/9111 [32:16<00:00,  4.71it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the MTCNN face detector\n",
    "detector = MTCNN()\n",
    "\n",
    "def crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3):\n",
    "    \"\"\"\n",
    "    Detects faces using MTCNN and ensures both ears, hair, and part of the neck are visible\n",
    "    while limiting clothing visibility.\n",
    "\n",
    "    :param input_folder: Path to dataset folder with images.\n",
    "    :param output_folder: Path to save cropped face images.\n",
    "    :param scale_w: Factor to expand bounding box width (default = 1.5).\n",
    "    :param scale_h: Factor to expand bounding box height (default = 1.4).\n",
    "    :param neck_reduction_factor: Factor to reduce neck visibility (default = 0.3).\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Process each image in the folder\n",
    "    for filename in tqdm(os.listdir(input_folder), desc=\"Processing Images\"):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Error loading {filename}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            h, w, _ = image.shape\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Detect faces\n",
    "            faces = detector.detect_faces(image_rgb)\n",
    "\n",
    "            if faces:\n",
    "                for face in faces:\n",
    "                    x, y, w_bbox, h_bbox = face['box']\n",
    "\n",
    "                    # Expand width equally on both sides for ears\n",
    "                    new_w = int(w_bbox * scale_w)\n",
    "                    x = x - int((new_w - w_bbox) // 2)  # Shift left to balance expansion\n",
    "\n",
    "                    # Expand height but reduce lower part (neck)\n",
    "                    new_h = int(h_bbox * scale_h)\n",
    "                    y = y - int((new_h - h_bbox) * 0.2)  # Move up slightly for forehead/hair\n",
    "                    new_h = new_h - int(h_bbox * neck_reduction_factor)  # Reduce lower neck exposure\n",
    "\n",
    "                    # Ensure the box stays within the image boundaries\n",
    "                    x = max(0, x)\n",
    "                    y = max(0, y)\n",
    "                    new_w = min(new_w, image.shape[1] - x)\n",
    "                    new_h = min(new_h, image.shape[0] - y)\n",
    "\n",
    "                    # Crop the expanded face region\n",
    "                    face_crop = image[y:y+new_h, x:x+new_w]\n",
    "\n",
    "                    # Save the cropped face\n",
    "                    output_path = os.path.join(output_folder, filename)\n",
    "                    cv2.imwrite(output_path, face_crop)\n",
    "                    break  # Only save the first detected face\n",
    "\n",
    "            else:\n",
    "                print(f\"No face detected in {filename}\")\n",
    "\n",
    "# Example Usage\n",
    "input_folder = \"/home/lab-08/Desktop/Emotion /Happy\"  # Path to dataset images\n",
    "output_folder =  \"/home/lab-08/Desktop/Cropped_faces /Happy\"   # Folder to save cropped faces\n",
    "crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bf2ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   2%|▍                    | 105/4621 [00:11<07:39,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0021262.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   3%|▋                    | 160/4621 [00:16<05:08, 14.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0008479.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  10%|██▏                  | 483/4621 [00:51<10:35,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.506342~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  15%|███                  | 681/4621 [01:15<10:07,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.232290~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  15%|███                  | 685/4621 [01:16<09:09,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.506278~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  16%|███▍                 | 753/4621 [01:22<04:18, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0027841.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  23%|████▋               | 1074/4621 [01:54<07:19,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231859~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  24%|████▊               | 1103/4621 [01:58<06:19,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0024410.jpg\n",
      "No face detected in image0018538.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  25%|████▉               | 1150/4621 [02:03<06:13,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0dbea111f59a2ee490cb7678671d596fb45f37c1d44a1df6df871fd0~angry.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  25%|█████               | 1165/4621 [02:05<05:43, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.571750~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  26%|█████▏              | 1208/4621 [02:09<04:08, 13.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0027687.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  28%|█████▋              | 1310/4621 [02:19<06:14,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in df01ef882d61a4f5fec618cdd1091a15c8bfc305adc35fdde64c0520~angry.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  29%|█████▋              | 1326/4621 [02:20<04:10, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0030632.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  30%|██████              | 1394/4621 [02:34<11:38,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231571~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  35%|██████▉             | 1602/4621 [02:57<05:52,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.232249~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  39%|███████▊            | 1791/4621 [03:19<06:14,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.571124~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  40%|███████▉            | 1830/4621 [03:25<05:43,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.505252~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  40%|████████            | 1850/4621 [03:27<05:38,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.571191~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  40%|████████            | 1868/4621 [03:29<03:52, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0028721.jpg\n",
      "No face detected in 1f2296d02dd48924d16cbac23fdfccf8ef80d45af3609f6da667dfba~angry.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  43%|████████▌           | 1974/4621 [03:40<05:08,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0025093.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  46%|█████████▏          | 2137/4621 [04:01<04:47,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0022573.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  48%|█████████▌          | 2221/4621 [04:11<03:43, 10.76it/s]2025-04-24 12:34:57.129271: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:  48%|█████████▌          | 2223/4621 [04:11<03:28, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231432~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  49%|█████████▋          | 2248/4621 [04:22<50:07,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 4b33a2f540fd37977aca8ede305989e23e76738f89c1c16ca9a2a620~angry.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  50%|██████████          | 2317/4621 [04:31<04:01,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.232309~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  50%|██████████          | 2333/4621 [04:32<03:18, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.571350~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  52%|██████████▍         | 2406/4621 [04:42<03:59,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231602~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  53%|██████████▋         | 2466/4621 [04:55<04:07,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0029352.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  55%|███████████         | 2553/4621 [05:05<03:48,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0008096.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  58%|███████████▋        | 2687/4621 [05:18<02:07, 15.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.232030~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  59%|███████████▉        | 2746/4621 [05:25<03:21,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0004946.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  60%|███████████▉        | 2760/4621 [05:26<02:13, 13.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0029565.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  60%|████████████        | 2793/4621 [05:30<02:39, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0010724.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  62%|████████████▎       | 2847/4621 [05:35<03:57,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231854~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  62%|████████████▍       | 2864/4621 [05:37<03:16,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0026821.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  66%|█████████████▏      | 3035/4621 [05:56<02:11, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0003876.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  69%|█████████████▊      | 3189/4621 [06:12<02:42,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231829~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  70%|█████████████▉      | 3223/4621 [06:16<02:22,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0017765.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  70%|█████████████▉      | 3230/4621 [06:17<03:56,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231882~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  73%|██████████████▌     | 3362/4621 [06:34<02:36,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0027870.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  75%|██████████████▉     | 3449/4621 [06:43<01:30, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0023821.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  77%|███████████████▎    | 3542/4621 [06:51<01:38, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0028069.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  79%|███████████████▉    | 3672/4621 [07:02<01:07, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0009062.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  80%|████████████████    | 3712/4621 [07:06<01:37,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231444~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  81%|████████████████▏   | 3730/4621 [07:07<01:16, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231934~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  81%|████████████████▏   | 3737/4621 [07:08<01:40,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231403~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  81%|████████████████▎   | 3761/4621 [07:11<01:15, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.571938~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  82%|████████████████▎   | 3776/4621 [07:13<01:50,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.232246~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  83%|████████████████▌   | 3813/4621 [07:20<02:09,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0027746.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  83%|████████████████▌   | 3839/4621 [07:23<01:34,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.232321~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  84%|████████████████▊   | 3895/4621 [07:30<01:21,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231837~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  86%|█████████████████▏  | 3977/4621 [07:39<01:31,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231940~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  87%|█████████████████▎  | 4002/4621 [07:41<00:45, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.231958~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  90%|██████████████████  | 4161/4621 [07:59<00:43, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0015819.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  94%|██████████████████▊ | 4345/4621 [08:20<00:23, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0028169.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  96%|███████████████████ | 4418/4621 [08:26<00:17, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.232109~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  96%|███████████████████▎| 4448/4621 [08:29<00:19,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.506936~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  96%|███████████████████▎| 4457/4621 [08:30<00:21,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0026091.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  98%|███████████████████▋| 4548/4621 [08:43<00:05, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0020036.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  99%|███████████████████▊| 4590/4621 [08:46<00:02, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.571267~angry.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|████████████████████| 4621/4621 [08:49<00:00,  8.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the MTCNN face detector\n",
    "detector = MTCNN()\n",
    "\n",
    "def crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3):\n",
    "    \"\"\"\n",
    "    Detects faces using MTCNN and ensures both ears, hair, and part of the neck are visible\n",
    "    while limiting clothing visibility.\n",
    "\n",
    "    :param input_folder: Path to dataset folder with images.\n",
    "    :param output_folder: Path to save cropped face images.\n",
    "    :param scale_w: Factor to expand bounding box width (default = 1.5).\n",
    "    :param scale_h: Factor to expand bounding box height (default = 1.4).\n",
    "    :param neck_reduction_factor: Factor to reduce neck visibility (default = 0.3).\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Process each image in the folder\n",
    "    for filename in tqdm(os.listdir(input_folder), desc=\"Processing Images\"):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Error loading {filename}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            h, w, _ = image.shape\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Detect faces\n",
    "            faces = detector.detect_faces(image_rgb)\n",
    "\n",
    "            if faces:\n",
    "                for face in faces:\n",
    "                    x, y, w_bbox, h_bbox = face['box']\n",
    "\n",
    "                    # Expand width equally on both sides for ears\n",
    "                    new_w = int(w_bbox * scale_w)\n",
    "                    x = x - int((new_w - w_bbox) // 2)  # Shift left to balance expansion\n",
    "\n",
    "                    # Expand height but reduce lower part (neck)\n",
    "                    new_h = int(h_bbox * scale_h)\n",
    "                    y = y - int((new_h - h_bbox) * 0.2)  # Move up slightly for forehead/hair\n",
    "                    new_h = new_h - int(h_bbox * neck_reduction_factor)  # Reduce lower neck exposure\n",
    "\n",
    "                    # Ensure the box stays within the image boundaries\n",
    "                    x = max(0, x)\n",
    "                    y = max(0, y)\n",
    "                    new_w = min(new_w, image.shape[1] - x)\n",
    "                    new_h = min(new_h, image.shape[0] - y)\n",
    "\n",
    "                    # Crop the expanded face region\n",
    "                    face_crop = image[y:y+new_h, x:x+new_w]\n",
    "\n",
    "                    # Save the cropped face\n",
    "                    output_path = os.path.join(output_folder, filename)\n",
    "                    cv2.imwrite(output_path, face_crop)\n",
    "                    break  # Only save the first detected face\n",
    "\n",
    "            else:\n",
    "                print(f\"No face detected in {filename}\")\n",
    "\n",
    "# Example Usage\n",
    "input_folder = \"/home/lab-08/Desktop/Emotion /Angry\"  # Path to dataset images\n",
    "output_folder =  \"/home/lab-08/Desktop/Cropped_faces /Angry\"   # Folder to save cropped faces\n",
    "crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4b4b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   1%|▏                    | 108/9194 [00:21<15:56,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in ffhq_1976.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   5%|▉                    | 436/9194 [01:09<17:02,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.171786f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   5%|█                    | 463/9194 [01:13<16:12,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0b4f11c34755520e5838f4946ec606008835c744e3a6cfc70ef440c1f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   8%|█▊                   | 781/9194 [02:00<25:19,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0cb3224bf017f7c200750c1ee5d5bee9806de497399df00cdbcac337f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   9%|█▊                   | 802/9194 [02:02<13:50, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0f21cae9eb345f3bbbd62856317910c2e2ce7c0cfde531fbe9da3769f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   9%|█▉                   | 873/9194 [02:12<15:55,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.171726f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  10%|██                   | 921/9194 [02:19<21:54,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.171863f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  11%|██▏                 | 1024/9194 [02:38<24:33,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.171768f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  14%|██▋                 | 1242/9194 [03:06<13:19,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in ffhq_1681.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  14%|██▊                 | 1287/9194 [03:13<26:41,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278151f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  16%|███▏                | 1472/9194 [03:42<21:08,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0b79824fc112df47c8a5122be360ba4d35a420f966cc1990e8de5292f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  17%|███▎                | 1523/9194 [03:51<13:31,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277730f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  17%|███▎                | 1549/9194 [03:54<16:14,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 1b5bb491c1e1419cb5360467621ff62e6aaf3f6342b14d36a149a41ef.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  18%|███▌                | 1639/9194 [04:08<12:22, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278043f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  18%|███▌                | 1649/9194 [04:09<13:29,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0d70f94cb6fae582dd83ddf209b8fd28a153487f9700410c23bd426df.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  19%|███▋                | 1707/9194 [04:18<17:48,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277798f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  19%|███▊                | 1777/9194 [04:28<18:07,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0c779da04d9bcd2e18a30bf72352f69aee5b8964936eeb8272a70f5cf.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  20%|████                | 1879/9194 [04:43<13:32,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278081f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  21%|████                | 1886/9194 [04:44<11:09, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278315f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  24%|████▊               | 2217/9194 [05:40<14:53,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278072f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  24%|████▉               | 2243/9194 [05:48<27:09,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278013f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  27%|█████▍              | 2525/9194 [07:25<30:52,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0015518.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  30%|██████              | 2781/9194 [08:05<15:02,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277666f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  32%|██████▎             | 2900/9194 [08:39<36:23,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277722f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  32%|██████▎             | 2914/9194 [08:44<20:32,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in ffhq_94.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  32%|██████▎             | 2922/9194 [08:45<12:46,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278217f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  34%|██████▊             | 3152/9194 [09:28<24:45,  4.07it/s]2025-04-24 12:49:04.362794: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:  34%|██████▊             | 3154/9194 [09:28<21:48,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.171855f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  35%|██████▉             | 3177/9194 [09:31<09:42, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.171775f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  36%|███████▎            | 3342/9194 [09:53<11:01,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0a514249601d7788d5c507f07091b073289293c87c7b45b4a830dbcdf.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  37%|███████▎            | 3359/9194 [09:55<09:41, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277646f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  38%|███████▌            | 3460/9194 [10:17<09:35,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278048f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  38%|███████▋            | 3532/9194 [10:29<11:38,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.171735f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  41%|████████▏           | 3766/9194 [11:08<13:10,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0c384f736a80d7a1357714c7bb037e9fbba91b0b4f5aa3ba23803222f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  43%|████████▌           | 3956/9194 [11:38<13:35,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0e70655a3703c3b9229dea2b33331eb8e81e01903eb0d988ca42dd95f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  43%|████████▋           | 3968/9194 [11:40<07:58, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278292f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  46%|█████████▏          | 4214/9194 [12:19<10:13,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.452672f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  47%|█████████▎          | 4306/9194 [12:34<17:49,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0ddaf104f98b9f0f84a719b13eafa90cc5b28f093bf51c365af3106ff.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  47%|█████████▍          | 4328/9194 [12:37<13:20,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 1a7314bebb1e143c2252fcb8d5907a8300cc0090d0ad20c2d866673df.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  51%|██████████▏         | 4706/9194 [13:46<07:12, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0d971ec74c3776b01dc5997eb1c203eba1f09493ac93f36330757595f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  51%|██████████▎         | 4725/9194 [13:52<32:38,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278278f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  53%|██████████▌         | 4839/9194 [14:10<11:57,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278360f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  54%|██████████▊         | 4946/9194 [14:25<10:39,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278472f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  54%|██████████▊         | 4967/9194 [14:28<08:14,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277720f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  55%|█████████▉        | 5054/9194 [14:59<2:00:20,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278015f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  58%|███████████▌        | 5319/9194 [15:36<12:58,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0a2b9e17288dfd235d3586548825ce47191efa55fbd5982feb932fc5f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  64%|████████████▋       | 5859/9194 [17:12<06:18,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.452763f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  64%|████████████▊       | 5874/9194 [17:13<04:46, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0c85094de68403031648eeaa058c3bfb0e59c6b5abd81deafe47ce56f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  66%|█████████████▏      | 6059/9194 [17:41<06:28,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278222f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  69%|█████████████▋      | 6310/9194 [18:20<05:27,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277649f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  71%|██████████████▏     | 6502/9194 [18:52<04:42,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0fb727b46e2c8f83e314bbfe06e1a90fe6c16c480cd98183ecd2ee69f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  73%|██████████████▋     | 6750/9194 [19:32<05:01,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0c1882a8b3f731e3d663f040bcd618db9df51d16cfd2bd3409b0cd8af.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  76%|███████████████▏    | 6986/9194 [20:12<05:36,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0c87666823949cfe9676d966448b94a68594ce2d9a9c1cbdfa5cabbbf.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  76%|███████████████▏    | 6990/9194 [20:12<05:11,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in ffhq_2536.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  78%|███████████████▌    | 7141/9194 [20:38<03:37,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.452704f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  78%|███████████████▌    | 7169/9194 [20:44<05:05,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0bd95dd1ceadcc0a3fe37d8f619770bd5445bee6312c40254207b960f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  80%|███████████████▉    | 7335/9194 [21:17<02:52, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278283f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  80%|████████████████    | 7377/9194 [21:31<06:02,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.452698f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  84%|████████████████▋   | 7698/9194 [22:34<05:43,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278453f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  84%|████████████████▊   | 7736/9194 [22:41<02:03, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278100f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  87%|█████████████████▎  | 7955/9194 [23:26<04:25,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277906f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  87%|█████████████████▎  | 7964/9194 [23:28<03:22,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277857f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  87%|█████████████████▎  | 7979/9194 [23:30<02:36,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0c74e4d748038277e98ed0edb4283591743c5cc14130b25ebfe3cdf9f.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  87%|█████████████████▍  | 7997/9194 [23:34<01:55, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277682f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  91%|██████████████████▏ | 8334/9194 [25:01<01:46,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.278370f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  92%|██████████████████▍ | 8496/9194 [25:26<01:10,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0a86a2568d0e6fee27eff19fd89f2595ba1616c86c451ae4e0a2f6cdf.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  93%|██████████████████▋ | 8564/9194 [25:36<01:18,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277898f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  97%|███████████████████▎| 8879/9194 [26:24<01:41,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.277634f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  97%|███████████████████▍| 8935/9194 [26:34<01:10,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in ffhq_899.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|████████████████████| 9194/9194 [27:34<00:00,  5.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the MTCNN face detector\n",
    "detector = MTCNN()\n",
    "\n",
    "def crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3):\n",
    "    \"\"\"\n",
    "    Detects faces using MTCNN and ensures both ears, hair, and part of the neck are visible\n",
    "    while limiting clothing visibility.\n",
    "\n",
    "    :param input_folder: Path to dataset folder with images.\n",
    "    :param output_folder: Path to save cropped face images.\n",
    "    :param scale_w: Factor to expand bounding box width (default = 1.5).\n",
    "    :param scale_h: Factor to expand bounding box height (default = 1.4).\n",
    "    :param neck_reduction_factor: Factor to reduce neck visibility (default = 0.3).\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Process each image in the folder\n",
    "    for filename in tqdm(os.listdir(input_folder), desc=\"Processing Images\"):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Error loading {filename}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            h, w, _ = image.shape\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Detect faces\n",
    "            faces = detector.detect_faces(image_rgb)\n",
    "\n",
    "            if faces:\n",
    "                for face in faces:\n",
    "                    x, y, w_bbox, h_bbox = face['box']\n",
    "\n",
    "                    # Expand width equally on both sides for ears\n",
    "                    new_w = int(w_bbox * scale_w)\n",
    "                    x = x - int((new_w - w_bbox) // 2)  # Shift left to balance expansion\n",
    "\n",
    "                    # Expand height but reduce lower part (neck)\n",
    "                    new_h = int(h_bbox * scale_h)\n",
    "                    y = y - int((new_h - h_bbox) * 0.2)  # Move up slightly for forehead/hair\n",
    "                    new_h = new_h - int(h_bbox * neck_reduction_factor)  # Reduce lower neck exposure\n",
    "\n",
    "                    # Ensure the box stays within the image boundaries\n",
    "                    x = max(0, x)\n",
    "                    y = max(0, y)\n",
    "                    new_w = min(new_w, image.shape[1] - x)\n",
    "                    new_h = min(new_h, image.shape[0] - y)\n",
    "\n",
    "                    # Crop the expanded face region\n",
    "                    face_crop = image[y:y+new_h, x:x+new_w]\n",
    "\n",
    "                    # Save the cropped face\n",
    "                    output_path = os.path.join(output_folder, filename)\n",
    "                    cv2.imwrite(output_path, face_crop)\n",
    "                    break  # Only save the first detected face\n",
    "\n",
    "            else:\n",
    "                print(f\"No face detected in {filename}\")\n",
    "\n",
    "# Example Usage\n",
    "input_folder = \"/home/lab-08/Desktop/Emotion /Neutral\"  # Path to dataset images\n",
    "output_folder =  \"/home/lab-08/Desktop/Cropped_faces /Neutral\"   # Folder to save cropped faces\n",
    "crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ccf5aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   3%|▌                    | 189/6923 [00:28<10:52, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.6125.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   3%|▋                    | 212/6923 [00:32<21:44,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0021857.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   4%|▉                    | 306/6923 [00:48<18:40,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.6074.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   6%|█▎                   | 415/6923 [01:05<21:55,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 7f27ff0a15350555550d31bb769b1e3b7387b5825554d30a81f5801d.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   7%|█▍                   | 467/6923 [01:14<12:06,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0027102.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   8%|█▋                   | 552/6923 [01:26<24:25,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.6178.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  10%|██                   | 662/6923 [01:42<17:33,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0002875.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  10%|██                   | 688/6923 [01:47<18:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.568118.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  11%|██▎                  | 744/6923 [01:55<08:36, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0021281.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  11%|██▎                  | 756/6923 [01:57<12:32,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0021786.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  11%|██▎                  | 779/6923 [02:00<12:13,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 6ace5e4e54241964882c620d8c466250361bc9d86ca3bb9534a9db21.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  12%|██▌                  | 852/6923 [02:14<49:02,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0017060.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  13%|██▋                  | 886/6923 [02:21<13:30,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 6da1050ad501609afc7db07803def78bcf06fa550e2fc8c33a9962dc.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  13%|██▊                  | 909/6923 [02:24<13:00,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 1c5423ca78048017254144f19f6351c23f5c20c5c9280ba97dcd1bc7.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  13%|██▊                  | 925/6923 [02:27<15:15,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.499014.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  14%|██▉                  | 987/6923 [02:36<14:33,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 1bef8480adf22d56e41a73dc01284db1d244b98b9993ff456a4d2bcd.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  16%|███                 | 1081/6923 [02:51<15:16,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 1edb45e2966c495c3e14bf2bb72a799aaea32427fd9166fd5043f181.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  17%|███▎                | 1160/6923 [03:02<09:09, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.252195.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  21%|████▏               | 1469/6923 [03:45<10:32,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 6a5a8cb39f5e6a8188845d3c9356d146133d75687a5501e690f9e2d0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  22%|████▎               | 1503/6923 [03:50<14:13,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0bee07cd92c63a466cad3710e6533d55ba8a452cf1217c5a782e7748.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  23%|████▌               | 1559/6923 [03:58<09:59,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.5900.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  24%|████▋               | 1638/6923 [04:10<07:37, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 3f185bccf011076ff3ef0cc797f401ac7e65102938c32ce34f85b1b7.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  24%|████▊               | 1664/6923 [04:13<12:29,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.5947.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  24%|████▊               | 1671/6923 [04:13<07:51, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0002385.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  24%|████▊               | 1687/6923 [04:15<09:39,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.251951.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  26%|█████               | 1772/6923 [04:30<08:11, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.499234.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  27%|█████▍              | 1897/6923 [04:53<18:51,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.5687.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  28%|█████▌              | 1927/6923 [04:58<05:21, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0030279.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  28%|█████▌              | 1935/6923 [04:59<10:33,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0025116.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  31%|██████▏             | 2138/6923 [05:34<19:02,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 4d2d54d764da0f1b5f1760c4e21b4d2b82c2ed81720855e8343ff6f0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  31%|██████▎             | 2164/6923 [05:38<15:12,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.6159.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  32%|██████▍             | 2211/6923 [05:46<09:17,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0020472.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  35%|██████▉             | 2416/6923 [06:15<07:20, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.5881.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  35%|███████             | 2445/6923 [06:18<07:34,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.499185.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  36%|███████▏            | 2473/6923 [06:22<12:36,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0d8449949a36d5a17b6df21ccae854e457f6d8f5ac53a4d9874b4952.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  39%|███████▊            | 2696/6923 [07:10<08:25,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.5736.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  40%|███████▉            | 2757/6923 [07:19<11:30,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.6193.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  42%|████████▍           | 2912/6923 [07:46<07:07,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.5683.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  43%|████████▌           | 2973/6923 [07:54<10:25,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 4cd57db64df39d755dd10da01a8d32aca52a5991c9dd411fed09eb85.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  44%|████████▊           | 3045/6923 [08:09<06:04, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.164233.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  45%|████████▉           | 3101/6923 [08:17<05:47, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 2ea80de8ef9df0e73026c8ad35011cc2ba56dfdbe16c88f67303db35.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  46%|█████████           | 3156/6923 [08:27<06:48,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 2eb3e8afec39e261f819b682d9a4b4ddffe5b15c597134b6aba1b826.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  46%|█████████▎          | 3210/6923 [08:36<10:45,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0010950.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  47%|█████████▎          | 3230/6923 [08:39<07:55,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.499316.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  47%|█████████▎          | 3242/6923 [08:41<07:20,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.141340.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  48%|█████████▌          | 3311/6923 [08:52<05:35, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0020054.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  49%|█████████▊          | 3385/6923 [09:04<07:24,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.141263.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  49%|█████████▊          | 3411/6923 [09:08<06:27,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.499092.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  51%|██████████▏         | 3522/6923 [09:26<08:38,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0030269.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  52%|██████████▍         | 3616/6923 [09:39<06:48,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.6029.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  52%|██████████▍         | 3631/6923 [09:43<16:05,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.6147.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  55%|██████████▉         | 3785/6923 [10:08<05:12, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0027319.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  56%|███████████▏        | 3875/6923 [10:20<05:18,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0006154.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  57%|███████████▎        | 3928/6923 [10:27<07:02,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0029795.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  63%|████████████▌       | 4337/6923 [11:26<05:35,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.6004.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  63%|████████████▌       | 4365/6923 [11:31<05:06,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.152144.png\n",
      "No face detected in 0abe4552facf8407e15e97608fed97c0a2c551c944a4d3e53c16a7b7.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  64%|████████████▊       | 4451/6923 [11:42<04:47,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.6155.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  66%|█████████████       | 4537/6923 [11:54<06:51,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 6ed72003ed0bed3ba28d4f332b14256cdf1fa5ab804ab84bdb5d53c4.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  68%|█████████████▌      | 4695/6923 [12:15<05:41,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0aa23504dc30efb6e392c5fee838a1b5c8281fd2062a4a9902a9b392.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  68%|█████████████▋      | 4742/6923 [12:22<03:42,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0024036.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  69%|█████████████▊      | 4776/6923 [12:33<10:10,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0023559.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  70%|█████████████▉      | 4824/6923 [12:39<04:17,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 2a5de7241ee63e48ae7a8ff636fe33ef566dd2af283453b7e3b13c0b.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  73%|██████████████▌     | 5022/6923 [13:11<04:15,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0e735473adb1318fa37bd58519ec0be7e1d8b87587168a88a8cb8000.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  73%|██████████████▌     | 5046/6923 [13:16<05:36,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0027160.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  75%|███████████████     | 5211/6923 [13:48<04:52,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.499302.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  77%|███████████████▍    | 5333/6923 [14:06<02:56,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 5c685d82d0bb73ee91e12660f542b39537f4f4a3b266c89da7c7b3fb.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  79%|███████████████▋    | 5450/6923 [14:31<03:29,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0025638.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  79%|███████████████▊    | 5483/6923 [14:40<04:04,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 2dfe146610d191f57718741b668aca0a70ad45bf2300a87824f2f14c.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  82%|████████████████▍   | 5705/6923 [15:22<04:22,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.252322.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  83%|████████████████▌   | 5715/6923 [15:24<04:54,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.6240.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  85%|█████████████████   | 5898/6923 [15:52<02:36,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.163836.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  86%|█████████████████▏  | 5942/6923 [15:59<02:06,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.499357.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  86%|█████████████████▏  | 5962/6923 [16:01<01:36, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0a3b3058528fc68de17b75d06d05490be8e3b5cfb9917320f4031d2b.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  87%|█████████████████▍  | 6038/6923 [16:15<02:28,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0026957.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  92%|██████████████████▎ | 6354/6923 [17:03<00:56, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 7c419c59e12d8abbec132a784492b249cf50153bc93280548ea2f1b5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  93%|██████████████████▌ | 6445/6923 [17:19<00:44, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.499013.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  94%|██████████████████▋ | 6483/6923 [17:24<01:10,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 0de20eaaf3cc2da95bdf13d3b922455e5735fef52ee226b09970f2f5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  95%|██████████████████▉ | 6562/6923 [17:40<00:54,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 3fe07182bef881102001435738ba7e062b52fc3829b364c75bf7bebc.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  95%|███████████████████ | 6585/6923 [17:44<01:06,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in 5f757473b7c8d3f888493e8cd8b476c03e0762f0bc223b98743aacc8.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  96%|███████████████████▏| 6647/6923 [17:55<01:16,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.252384.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  97%|███████████████████▍| 6745/6923 [18:14<00:27,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.569717.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  98%|███████████████████▌| 6766/6923 [18:17<00:25,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0029241.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|███████████████████▉| 6893/6923 [18:39<00:03,  8.71it/s]2025-04-24 13:25:49.827036: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images: 100%|███████████████████▉| 6895/6923 [18:40<00:03,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.152855.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|███████████████████▉| 6907/6923 [18:41<00:01, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.499198.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|████████████████████| 6923/6923 [18:43<00:00,  6.16it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the MTCNN face detector\n",
    "detector = MTCNN()\n",
    "\n",
    "def crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3):\n",
    "    \"\"\"\n",
    "    Detects faces using MTCNN and ensures both ears, hair, and part of the neck are visible\n",
    "    while limiting clothing visibility.\n",
    "\n",
    "    :param input_folder: Path to dataset folder with images.\n",
    "    :param output_folder: Path to save cropped face images.\n",
    "    :param scale_w: Factor to expand bounding box width (default = 1.5).\n",
    "    :param scale_h: Factor to expand bounding box height (default = 1.4).\n",
    "    :param neck_reduction_factor: Factor to reduce neck visibility (default = 0.3).\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Process each image in the folder\n",
    "    for filename in tqdm(os.listdir(input_folder), desc=\"Processing Images\"):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Error loading {filename}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            h, w, _ = image.shape\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Detect faces\n",
    "            faces = detector.detect_faces(image_rgb)\n",
    "\n",
    "            if faces:\n",
    "                for face in faces:\n",
    "                    x, y, w_bbox, h_bbox = face['box']\n",
    "\n",
    "                    # Expand width equally on both sides for ears\n",
    "                    new_w = int(w_bbox * scale_w)\n",
    "                    x = x - int((new_w - w_bbox) // 2)  # Shift left to balance expansion\n",
    "\n",
    "                    # Expand height but reduce lower part (neck)\n",
    "                    new_h = int(h_bbox * scale_h)\n",
    "                    y = y - int((new_h - h_bbox) * 0.2)  # Move up slightly for forehead/hair\n",
    "                    new_h = new_h - int(h_bbox * neck_reduction_factor)  # Reduce lower neck exposure\n",
    "\n",
    "                    # Ensure the box stays within the image boundaries\n",
    "                    x = max(0, x)\n",
    "                    y = max(0, y)\n",
    "                    new_w = min(new_w, image.shape[1] - x)\n",
    "                    new_h = min(new_h, image.shape[0] - y)\n",
    "\n",
    "                    # Crop the expanded face region\n",
    "                    face_crop = image[y:y+new_h, x:x+new_w]\n",
    "\n",
    "                    # Save the cropped face\n",
    "                    output_path = os.path.join(output_folder, filename)\n",
    "                    cv2.imwrite(output_path, face_crop)\n",
    "                    break  # Only save the first detected face\n",
    "\n",
    "            else:\n",
    "                print(f\"No face detected in {filename}\")\n",
    "\n",
    "# Example Usage\n",
    "input_folder = \"/home/lab-08/Desktop/Emotion /Sad\"  # Path to dataset images\n",
    "output_folder =  \"/home/lab-08/Desktop/Cropped_faces /Sad\"   # Folder to save cropped faces\n",
    "crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820bae50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:56:58.959018: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-24 16:57:00.209341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745494020.574732   22731 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745494020.666460   22731 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-24 16:57:01.447236: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1745494033.123571   22731 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13899 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "Processing Images:   0%|                       | 3/1116 [00:01<07:55,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190098~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   1%|▏                      | 7/1116 [00:02<04:07,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.54473~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   1%|▏                     | 11/1116 [00:03<04:38,  3.97it/s]2025-04-24 16:57:19.615382: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:   1%|▎                     | 13/1116 [00:03<03:33,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol839~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   2%|▎                     | 17/1116 [00:04<03:50,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol782~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   3%|▌                     | 28/1116 [00:07<04:03,  4.47it/s]2025-04-24 16:57:23.359633: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:   3%|▌                     | 30/1116 [00:07<03:56,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol754~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   3%|▋                     | 33/1116 [00:08<03:38,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol434~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   3%|▋                     | 35/1116 [00:08<04:10,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol705~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:   3%|▋                     | 36/1116 [00:08<04:10,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190871~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   4%|▉                     | 48/1116 [00:11<03:40,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol446~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   5%|█                     | 55/1116 [00:12<03:14,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.18053~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   5%|█                     | 57/1116 [00:13<03:44,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol267~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   5%|█▏                    | 61/1116 [00:14<03:50,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.189961~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   6%|█▎                    | 67/1116 [00:15<04:21,  4.02it/s]2025-04-24 16:57:31.936991: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:   6%|█▎                    | 69/1116 [00:16<04:03,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol179~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   6%|█▍                    | 72/1116 [00:16<04:12,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol888~ahegao.png\n",
      "No face detected in lol680~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   7%|█▍                    | 74/1116 [00:17<03:42,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190890~ahegao.png\n",
      "No face detected in cropped_emotions.34889~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   7%|█▌                    | 78/1116 [00:17<03:23,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol812~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   8%|█▋                    | 84/1116 [00:19<03:04,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.16653~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   8%|█▋                    | 87/1116 [00:19<03:37,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol147~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   8%|█▊                    | 89/1116 [00:20<03:23,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol836~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:   8%|█▊                    | 90/1116 [00:20<03:24,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.30248~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   8%|█▊                    | 92/1116 [00:20<03:35,  4.75it/s]2025-04-24 16:57:36.928433: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:   8%|█▊                    | 93/1116 [00:20<03:05,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol430~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   9%|█▉                    | 99/1116 [00:22<03:57,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol868~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   9%|█▉                   | 103/1116 [00:23<03:09,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.35757~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:   9%|█▉                   | 104/1116 [00:23<03:04,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol863~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  10%|██                   | 111/1116 [00:24<03:03,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol88~ahegao.png\n",
      "No face detected in cropped_emotions.24479~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  10%|██▏                  | 113/1116 [00:25<03:23,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol25~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  10%|██▏                  | 115/1116 [00:25<03:20,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol3~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  10%|██▏                  | 117/1116 [00:25<03:13,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190836~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  11%|██▏                  | 119/1116 [00:26<03:12,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol873~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  11%|██▎                  | 122/1116 [00:26<02:56,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol365~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  12%|██▌                  | 133/1116 [00:29<03:06,  5.27it/s]2025-04-24 16:57:45.343798: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:  12%|██▌                  | 134/1116 [00:29<03:03,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol150~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  12%|██▌                  | 135/1116 [00:29<03:23,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol663~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  13%|██▋                  | 143/1116 [00:31<03:14,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.189917~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  13%|██▋                  | 145/1116 [00:31<03:21,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol813~ahegao.png\n",
      "No face detected in cropped_emotions.190908~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  13%|██▋                  | 146/1116 [00:31<03:33,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190374~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  13%|██▊                  | 148/1116 [00:32<03:12,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol635~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  13%|██▊                  | 149/1116 [00:32<03:36,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.189637~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  14%|██▉                  | 153/1116 [00:33<03:14,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol507~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  14%|██▉                  | 155/1116 [00:33<03:25,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol756~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  14%|██▉                  | 159/1116 [00:34<03:22,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol749~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  15%|███                  | 162/1116 [00:35<02:46,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol453~ahegao.png\n",
      "No face detected in lol246~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  15%|███▏                 | 170/1116 [00:36<03:08,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol517~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  15%|███▏                 | 171/1116 [00:36<03:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol671~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  15%|███▏                 | 172/1116 [00:37<03:14,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol424~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  16%|███▎                 | 174/1116 [00:37<03:02,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.40412~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  16%|███▎                 | 178/1116 [00:38<03:19,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol693~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  16%|███▎                 | 179/1116 [00:38<03:03,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol902~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  16%|███▍                 | 182/1116 [00:39<02:59,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.189976~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  17%|███▍                 | 185/1116 [00:39<02:28,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol85~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  17%|███▌                 | 190/1116 [00:40<03:02,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol684~ahegao.png\n",
      "No face detected in lol188~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  18%|███▋                 | 196/1116 [00:41<02:49,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol880~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  18%|███▊                 | 201/1116 [00:42<02:49,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol771~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  18%|███▊                 | 203/1116 [00:43<02:48,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol708~ahegao.png\n",
      "No face detected in cropped_emotions.190434~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  18%|███▊                 | 205/1116 [00:43<02:56,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.26299~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  19%|███▉                 | 208/1116 [00:44<02:58,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol652~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  19%|████                 | 214/1116 [00:45<02:56,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol42~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  20%|████                 | 218/1116 [00:46<02:31,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol727~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  21%|████▎                | 232/1116 [00:49<02:57,  4.99it/s]2025-04-24 16:58:05.308725: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:  21%|████▍                | 233/1116 [00:49<02:40,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol712~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  21%|████▍                | 234/1116 [00:49<03:01,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol719~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  21%|████▍                | 237/1116 [00:50<02:48,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.39494~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  21%|████▍                | 239/1116 [00:50<02:34,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol466~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  22%|████▌                | 240/1116 [00:50<02:44,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol205~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  22%|████▋                | 250/1116 [00:52<02:29,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.189247~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  22%|████▋                | 251/1116 [00:52<02:42,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol509~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  23%|████▉                | 262/1116 [00:54<02:41,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.191902~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  24%|████▉                | 265/1116 [00:55<03:09,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.191627~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  24%|█████                | 267/1116 [00:56<02:56,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol745~ahegao.png\n",
      "No face detected in cropped_emotions.20865~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  24%|█████                | 270/1116 [00:56<02:28,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.34154~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  24%|█████                | 271/1116 [00:56<02:38,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol826~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  25%|█████▏               | 276/1116 [00:57<02:44,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol503~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  25%|█████▎               | 284/1116 [00:59<02:48,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol344~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  26%|█████▍               | 290/1116 [01:00<02:47,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190654~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  26%|█████▍               | 291/1116 [01:01<02:58,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol872~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  27%|█████▌               | 297/1116 [01:02<02:51,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol607~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  27%|█████▋               | 299/1116 [01:02<02:27,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.41300~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  27%|█████▊               | 306/1116 [01:04<02:45,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.191595~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  28%|█████▊               | 311/1116 [01:05<02:36,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol305~ahegao.png\n",
      "No face detected in cropped_emotions.39186~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  29%|██████               | 321/1116 [01:07<02:50,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol571~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  29%|██████▏              | 327/1116 [01:08<02:47,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol516~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  30%|██████▎              | 335/1116 [01:10<02:37,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol670~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  30%|██████▎              | 336/1116 [01:10<02:37,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol288~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  30%|██████▍              | 340/1116 [01:11<02:53,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol877~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  31%|██████▌              | 347/1116 [01:12<02:19,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol787~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  31%|██████▌              | 348/1116 [01:12<02:12,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.188812~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  32%|██████▋              | 353/1116 [01:13<02:16,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol506~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  32%|██████▊              | 359/1116 [01:15<02:28,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol713~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  33%|██████▊              | 364/1116 [01:16<02:38,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol204~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  33%|██████▉              | 366/1116 [01:16<02:37,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol501~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  33%|██████▉              | 369/1116 [01:17<02:18,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol753~ahegao.png\n",
      "No face detected in lol707~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  34%|███████              | 377/1116 [01:18<02:26,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.53446~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  34%|███████▏             | 379/1116 [01:19<02:20,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol785~ahegao.png\n",
      "No face detected in lol512~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  34%|███████▏             | 380/1116 [01:19<02:38,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol283~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  35%|███████▎             | 386/1116 [01:20<01:57,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol452~ahegao.png\n",
      "No face detected in cropped_emotions.19760~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  36%|███████▌             | 400/1116 [01:22<01:46,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol61~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  36%|███████▌             | 402/1116 [01:23<02:25,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol140~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  37%|███████▋             | 409/1116 [01:24<01:56,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190023~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  37%|███████▊             | 416/1116 [01:26<02:48,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol889~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  38%|███████▉             | 422/1116 [01:27<02:21,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol401~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  38%|████████             | 427/1116 [01:28<02:19,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol761~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  39%|████████▏            | 435/1116 [01:29<01:56,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol815~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  40%|████████▍            | 446/1116 [01:32<02:03,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol75~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  40%|████████▍            | 447/1116 [01:32<02:43,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.191104~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  41%|████████▌            | 456/1116 [01:34<02:22,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol750~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  41%|████████▋            | 460/1116 [01:35<02:25,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol522~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  41%|████████▋            | 461/1116 [01:35<02:24,  4.54it/s]2025-04-24 16:58:52.108501: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:  41%|████████▋            | 463/1116 [01:36<02:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol676~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  42%|████████▊            | 465/1116 [01:36<02:06,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol100~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  43%|████████▉            | 478/1116 [01:39<01:53,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.16382~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  43%|█████████            | 481/1116 [01:39<01:52,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol448~ahegao.png\n",
      "No face detected in lol843~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  44%|█████████▏           | 490/1116 [01:41<01:31,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol237~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  44%|█████████▎           | 496/1116 [01:42<01:51,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol300~ahegao.png\n",
      "No face detected in lol901~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  45%|█████████▎           | 498/1116 [01:43<01:59,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol190~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  45%|█████████▍           | 502/1116 [01:43<01:56,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol141~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  46%|█████████▌           | 511/1116 [01:45<02:02,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.32423~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  47%|█████████▊           | 520/1116 [01:48<02:05,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol369~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  47%|█████████▊           | 521/1116 [01:48<02:15,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol640~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  47%|█████████▉           | 526/1116 [01:49<02:07,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol460~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  47%|█████████▉           | 527/1116 [01:49<02:12,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol603~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  47%|█████████▉           | 530/1116 [01:50<01:57,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol436~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  48%|██████████           | 532/1116 [01:50<01:57,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.20048~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  48%|██████████           | 536/1116 [01:51<01:46,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol121~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  49%|██████████▏          | 544/1116 [01:53<02:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190479~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  49%|██████████▎          | 545/1116 [01:53<01:59,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol530~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  49%|██████████▎          | 547/1116 [01:53<01:54,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol360~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  49%|██████████▎          | 551/1116 [01:54<01:52,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol331~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  50%|██████████▍          | 553/1116 [01:55<01:43,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol838~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  50%|██████████▍          | 554/1116 [01:55<01:43,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol524~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  50%|██████████▌          | 558/1116 [01:56<02:09,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol230~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  50%|██████████▌          | 561/1116 [01:56<01:53,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol622~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  51%|██████████▋          | 565/1116 [01:57<02:11,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol582~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  51%|██████████▋          | 567/1116 [01:58<02:04,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol853~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  51%|██████████▊          | 572/1116 [01:59<01:54,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol543~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  51%|██████████▊          | 574/1116 [01:59<01:52,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.19989~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  52%|██████████▊          | 575/1116 [02:00<01:56,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol699~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  52%|██████████▊          | 576/1116 [02:00<02:01,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.191782~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  52%|██████████▉          | 578/1116 [02:00<02:04,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol531~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  52%|██████████▉          | 584/1116 [02:02<02:16,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol725~ahegao.png\n",
      "No face detected in lol500~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  53%|███████████          | 587/1116 [02:03<01:51,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.191967~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  53%|███████████          | 588/1116 [02:03<02:05,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol795~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  53%|███████████▏         | 596/1116 [02:05<01:56,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol238~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  54%|███████████▎         | 599/1116 [02:05<02:10,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol561~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  54%|███████████▎         | 601/1116 [02:06<02:04,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol807~ahegao.png\n",
      "No face detected in lol93~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  54%|███████████▎         | 604/1116 [02:06<01:20,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.188337~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  54%|███████████▍         | 606/1116 [02:07<01:29,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol235~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  55%|███████████▍         | 610/1116 [02:07<01:25,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.52401~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  55%|███████████▌         | 612/1116 [02:08<01:36,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol165~ahegao.png\n",
      "No face detected in lol730~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  55%|███████████▌         | 613/1116 [02:08<01:29,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol617~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  55%|███████████▌         | 615/1116 [02:08<01:31,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol835~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  55%|███████████▌         | 617/1116 [02:09<01:35,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.22898~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  56%|███████████▊         | 627/1116 [02:11<01:25,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol118~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  56%|███████████▊         | 628/1116 [02:11<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.29250~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  57%|████████████         | 639/1116 [02:13<01:40,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.189288~ahegao.png\n",
      "No face detected in lol92~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  58%|████████████▏        | 645/1116 [02:15<01:49,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol529~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  58%|████████████▏        | 646/1116 [02:15<01:48,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol314~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  59%|████████████▎        | 654/1116 [02:16<01:35,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol772~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  59%|████████████▎        | 656/1116 [02:17<01:33,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol189~ahegao.png\n",
      "No face detected in lol675~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  59%|████████████▍        | 663/1116 [02:18<01:22,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol447~ahegao.png\n",
      "No face detected in cropped_emotions.54432~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  60%|████████████▌        | 666/1116 [02:19<01:22,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol681~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  60%|████████████▌        | 669/1116 [02:19<01:14,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol74~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  60%|████████████▋        | 674/1116 [02:20<01:21,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol421~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  62%|█████████████        | 693/1116 [02:24<01:32,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol655~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  63%|█████████████▏       | 699/1116 [02:25<01:33,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol287~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  63%|█████████████▏       | 701/1116 [02:26<01:28,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol128~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  64%|█████████████▎       | 709/1116 [02:28<01:34,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol206~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  64%|█████████████▍       | 715/1116 [02:29<01:22,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.36274~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  65%|█████████████▌       | 723/1116 [02:31<01:23,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol27~ahegao.png\n",
      "No face detected in lol486~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  66%|█████████████▊       | 731/1116 [02:32<01:24,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol673~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  66%|█████████████▊       | 736/1116 [02:33<01:24,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol22~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  66%|█████████████▉       | 738/1116 [02:34<01:21,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol107~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  66%|█████████████▉       | 740/1116 [02:34<01:20,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol180~ahegao.png\n",
      "No face detected in lol864~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  67%|██████████████       | 744/1116 [02:35<01:15,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190541~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  67%|██████████████       | 746/1116 [02:35<01:07,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol823~ahegao.png\n",
      "No face detected in lol277~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  67%|██████████████       | 750/1116 [02:36<01:11,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol137~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  68%|██████████████▎      | 758/1116 [02:38<01:16,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.38788~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  68%|██████████████▍      | 764/1116 [02:39<01:12,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol62~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  69%|██████████████▍      | 768/1116 [02:40<00:54,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.50274~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  69%|██████████████▌      | 772/1116 [02:41<01:01,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol317~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  69%|██████████████▌      | 775/1116 [02:41<00:58,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190203~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  70%|██████████████▋      | 778/1116 [02:42<01:03,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.16284~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  70%|██████████████▋      | 782/1116 [02:43<01:47,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol869~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  70%|██████████████▊      | 786/1116 [02:44<01:19,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol234~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  71%|██████████████▉      | 793/1116 [02:45<00:58,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol46~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  71%|██████████████▉      | 795/1116 [02:46<00:58,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol209~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  72%|███████████████▏     | 805/1116 [02:48<01:02,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol250~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  73%|███████████████▎     | 814/1116 [02:50<01:04,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol654~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  73%|███████████████▍     | 818/1116 [02:51<00:53,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol309~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  73%|███████████████▍     | 820/1116 [02:51<00:45,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190327~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  75%|███████████████▋     | 832/1116 [02:54<01:01,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol678~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  75%|███████████████▊     | 838/1116 [02:55<00:56,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol659~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  75%|███████████████▊     | 841/1116 [02:55<00:52,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol257~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  75%|███████████████▊     | 842/1116 [02:56<00:46,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol130~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  76%|███████████████▊     | 843/1116 [02:56<00:50,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol208~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  76%|███████████████▉     | 845/1116 [02:56<00:56,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol759~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  76%|███████████████▉     | 850/1116 [02:57<00:45,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.27578~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  77%|████████████████▏    | 859/1116 [02:59<00:45,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol286~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  77%|████████████████▏    | 862/1116 [03:00<00:45,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol458~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  77%|████████████████▎    | 864/1116 [03:00<00:47,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol338~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  78%|████████████████▎    | 868/1116 [03:01<00:49,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol91~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  78%|████████████████▎    | 869/1116 [03:01<00:49,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.44381~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  78%|████████████████▍    | 874/1116 [03:02<00:47,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol632~ahegao.png\n",
      "No face detected in cropped_emotions.188464~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  79%|████████████████▌    | 877/1116 [03:03<00:48,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol477~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  79%|████████████████▋    | 884/1116 [03:04<00:46,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol347~ahegao.png\n",
      "No face detected in lol251~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  80%|████████████████▋    | 888/1116 [03:05<00:45,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol416~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  80%|████████████████▊    | 891/1116 [03:06<00:40,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol820~ahegao.png\n",
      "No face detected in lol537~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  80%|████████████████▉    | 897/1116 [03:06<00:29,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.24333~ahegao.png\n",
      "No face detected in lol881~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  81%|████████████████▉    | 899/1116 [03:07<00:28,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol757~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  82%|█████████████████▏   | 914/1116 [03:10<00:38,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol343~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  83%|█████████████████▎   | 921/1116 [03:11<00:33,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190199~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  83%|█████████████████▍   | 927/1116 [03:12<00:31,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.20157~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  84%|█████████████████▌   | 935/1116 [03:14<00:35,  5.15it/s]2025-04-24 17:00:30.480297: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0,48,48,3] vs. [1,1,1,32]\n",
      "Processing Images:  84%|█████████████████▌   | 936/1116 [03:14<00:33,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol717~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  84%|█████████████████▋   | 941/1116 [03:15<00:40,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol849~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  85%|█████████████████▊   | 944/1116 [03:16<00:36,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190957~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  85%|█████████████████▊   | 946/1116 [03:16<00:31,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol875~ahegao.png\n",
      "No face detected in lol301~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  85%|█████████████████▉   | 951/1116 [03:17<00:27,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol345~ahegao.png\n",
      "No face detected in lol441~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  85%|█████████████████▉   | 952/1116 [03:17<00:28,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol775~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  87%|██████████████████▏  | 967/1116 [03:20<00:31,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol186~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  87%|██████████████████▎  | 974/1116 [03:22<00:31,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol412~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  88%|██████████████████▍  | 982/1116 [03:24<00:27,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol65~ahegao.png\n",
      "No face detected in lol803~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  88%|██████████████████▌  | 984/1116 [03:24<00:22,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol58~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  89%|██████████████████▋  | 990/1116 [03:25<00:22,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol222~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  89%|██████████████████▋  | 992/1116 [03:26<00:25,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol428~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  89%|██████████████████▊  | 998/1116 [03:27<00:25,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol324~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  90%|██████████████████  | 1006/1116 [03:29<00:24,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.191934~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  91%|██████████████████  | 1011/1116 [03:30<00:25,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.188948~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  92%|██████████████████▎ | 1022/1116 [03:33<00:22,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol883~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  92%|██████████████████▎ | 1024/1116 [03:33<00:20,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190598~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  92%|██████████████████▍ | 1026/1116 [03:33<00:20,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol904~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  93%|██████████████████▌ | 1037/1116 [03:36<00:15,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol346~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  93%|██████████████████▌ | 1039/1116 [03:36<00:15,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol674~ahegao.png\n",
      "No face detected in lol817~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  94%|██████████████████▋ | 1045/1116 [03:37<00:13,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol647~ahegao.png\n",
      "No face detected in lol547~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  94%|██████████████████▊ | 1049/1116 [03:38<00:12,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol662~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  95%|██████████████████▉ | 1060/1116 [03:40<00:09,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol73~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  95%|███████████████████ | 1062/1116 [03:41<00:09,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol131~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  95%|███████████████████ | 1065/1116 [03:41<00:11,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol182~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  96%|███████████████████ | 1067/1116 [03:42<00:10,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol706~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  96%|███████████████████▏| 1069/1116 [03:42<00:09,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol742~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  96%|███████████████████▏| 1073/1116 [03:43<00:07,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.190924~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  97%|███████████████████▍| 1083/1116 [03:45<00:06,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol6~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  97%|███████████████████▍| 1088/1116 [03:46<00:05,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol355~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  98%|███████████████████▌| 1093/1116 [03:47<00:04,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol467~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  98%|███████████████████▋| 1097/1116 [03:48<00:03,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol192~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  98%|███████████████████▋| 1098/1116 [03:48<00:03,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol51~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Images:  98%|███████████████████▋| 1099/1116 [03:48<00:04,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol844~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  99%|███████████████████▊| 1103/1116 [03:49<00:02,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol56~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|███████████████████▉| 1111/1116 [03:51<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in lol770~ahegao.png\n",
      "No face detected in cropped_emotions.190344~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|███████████████████▉| 1115/1116 [03:51<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.188921~ahegao.png\n",
      "No face detected in lol374~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|████████████████████| 1116/1116 [03:52<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in cropped_emotions.191775~ahegao.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the MTCNN face detector\n",
    "detector = MTCNN()\n",
    "\n",
    "def crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3):\n",
    "    \"\"\"\n",
    "    Detects faces using MTCNN and ensures both ears, hair, and part of the neck are visible\n",
    "    while limiting clothing visibility.\n",
    "\n",
    "    :param input_folder: Path to dataset folder with images.\n",
    "    :param output_folder: Path to save cropped face images.\n",
    "    :param scale_w: Factor to expand bounding box width (default = 1.5).\n",
    "    :param scale_h: Factor to expand bounding box height (default = 1.4).\n",
    "    :param neck_reduction_factor: Factor to reduce neck visibility (default = 0.3).\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Process each image in the folder\n",
    "    for filename in tqdm(os.listdir(input_folder), desc=\"Processing Images\"):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Error loading {filename}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            h, w, _ = image.shape\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Detect faces\n",
    "            faces = detector.detect_faces(image_rgb)\n",
    "\n",
    "            if faces:\n",
    "                for face in faces:\n",
    "                    x, y, w_bbox, h_bbox = face['box']\n",
    "\n",
    "                    # Expand width equally on both sides for ears\n",
    "                    new_w = int(w_bbox * scale_w)\n",
    "                    x = x - int((new_w - w_bbox) // 2)  # Shift left to balance expansion\n",
    "\n",
    "                    # Expand height but reduce lower part (neck)\n",
    "                    new_h = int(h_bbox * scale_h)\n",
    "                    y = y - int((new_h - h_bbox) * 0.2)  # Move up slightly for forehead/hair\n",
    "                    new_h = new_h - int(h_bbox * neck_reduction_factor)  # Reduce lower neck exposure\n",
    "\n",
    "                    # Ensure the box stays within the image boundaries\n",
    "                    x = max(0, x)\n",
    "                    y = max(0, y)\n",
    "                    new_w = min(new_w, image.shape[1] - x)\n",
    "                    new_h = min(new_h, image.shape[0] - y)\n",
    "\n",
    "                    # Crop the expanded face region\n",
    "                    face_crop = image[y:y+new_h, x:x+new_w]\n",
    "\n",
    "                    # Save the cropped face\n",
    "                    output_path = os.path.join(output_folder, filename)\n",
    "                    cv2.imwrite(output_path, face_crop)\n",
    "                    break  # Only save the first detected face\n",
    "\n",
    "            else:\n",
    "                print(f\"No face detected in {filename}\")\n",
    "\n",
    "# Example Usage\n",
    "input_folder = \"/home/lab-08/Downloads/expression/Ahegao\"  # Path to dataset images\n",
    "output_folder =  \"/home/lab-08/Downloads/Cropped_faces1/Ahegao\"   # Folder to save cropped faces\n",
    "crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "567d82bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   5%|█                     | 62/1229 [00:08<02:30,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0037230.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   8%|█▊                    | 99/1229 [00:12<02:22,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0042142.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  19%|████                 | 239/1229 [00:31<02:14,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0042255.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  22%|████▌                | 267/1229 [00:34<02:05,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0041298.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  32%|██████▊              | 396/1229 [00:52<01:51,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0039821.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  41%|████████▌            | 501/1229 [01:05<01:31,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0042240.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  90%|██████████████████  | 1108/1229 [02:22<00:14,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0038835.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|███████████████████▉| 1225/1229 [02:38<00:00,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image0042288.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|████████████████████| 1229/1229 [02:38<00:00,  7.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the MTCNN face detector\n",
    "detector = MTCNN()\n",
    "\n",
    "def crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3):\n",
    "    \"\"\"\n",
    "    Detects faces using MTCNN and ensures both ears, hair, and part of the neck are visible\n",
    "    while limiting clothing visibility.\n",
    "\n",
    "    :param input_folder: Path to dataset folder with images.\n",
    "    :param output_folder: Path to save cropped face images.\n",
    "    :param scale_w: Factor to expand bounding box width (default = 1.5).\n",
    "    :param scale_h: Factor to expand bounding box height (default = 1.4).\n",
    "    :param neck_reduction_factor: Factor to reduce neck visibility (default = 0.3).\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Process each image in the folder\n",
    "    for filename in tqdm(os.listdir(input_folder), desc=\"Processing Images\"):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Error loading {filename}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            h, w, _ = image.shape\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Detect faces\n",
    "            faces = detector.detect_faces(image_rgb)\n",
    "\n",
    "            if faces:\n",
    "                for face in faces:\n",
    "                    x, y, w_bbox, h_bbox = face['box']\n",
    "\n",
    "                    # Expand width equally on both sides for ears\n",
    "                    new_w = int(w_bbox * scale_w)\n",
    "                    x = x - int((new_w - w_bbox) // 2)  # Shift left to balance expansion\n",
    "\n",
    "                    # Expand height but reduce lower part (neck)\n",
    "                    new_h = int(h_bbox * scale_h)\n",
    "                    y = y - int((new_h - h_bbox) * 0.2)  # Move up slightly for forehead/hair\n",
    "                    new_h = new_h - int(h_bbox * neck_reduction_factor)  # Reduce lower neck exposure\n",
    "\n",
    "                    # Ensure the box stays within the image boundaries\n",
    "                    x = max(0, x)\n",
    "                    y = max(0, y)\n",
    "                    new_w = min(new_w, image.shape[1] - x)\n",
    "                    new_h = min(new_h, image.shape[0] - y)\n",
    "\n",
    "                    # Crop the expanded face region\n",
    "                    face_crop = image[y:y+new_h, x:x+new_w]\n",
    "\n",
    "                    # Save the cropped face\n",
    "                    output_path = os.path.join(output_folder, filename)\n",
    "                    cv2.imwrite(output_path, face_crop)\n",
    "                    break  # Only save the first detected face\n",
    "\n",
    "            else:\n",
    "                print(f\"No face detected in {filename}\")\n",
    "\n",
    "# Example Usage\n",
    "input_folder = \"/home/lab-08/Downloads/expression/disgust\"  # Path to dataset images\n",
    "output_folder =  \"/home/lab-08/Downloads/Cropped_faces1/disgust\"   # Folder to save cropped faces\n",
    "crop_faces_mtcnn_balanced_ears(input_folder, output_folder, scale_w=1.5, scale_h=1.4, neck_reduction_factor=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134c441-5663-4e59-afae-ed5c09eef8f2",
   "metadata": {},
   "source": [
    "For Image Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb1be39-3d0c-4e38-973f-36b401208ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing completed!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "input_folder = \"/home/lab-08/Downloads/Cropped_faces1/Ahegao\"  # Replace with your input folder path\n",
    "output_folder = \"/home/lab-08/Downloads/Expression1/Ahegao\" # Folder where cropped faces will be saved\n",
    "\n",
    "width, height = 600, 600  \n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img is not None:\n",
    "        resized_img = cv2.resize(img, (width, height))\n",
    "        cv2.imwrite(os.path.join(output_folder, filename), resized_img)\n",
    "\n",
    "print(\"Resizing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd387936-8ac4-4627-9786-530f0a140b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing completed!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "input_folder = \"/home/lab-08/Downloads/Cropped_faces1/disgust\"  # Replace with your input folder path\n",
    "output_folder = \"/home/lab-08/Downloads/Expression1/disgust\" # Folder where cropped faces will be saved\n",
    "\n",
    "width, height = 600, 600  \n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img is not None:\n",
    "        resized_img = cv2.resize(img, (width, height))\n",
    "        cv2.imwrite(os.path.join(output_folder, filename), resized_img)\n",
    "\n",
    "print(\"Resizing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6bc112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
