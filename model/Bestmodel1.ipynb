{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "POGGI9udgneV"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_path = '/content/drive/MyDrive/facecroppedexpression.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall('/content/expression')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define paths (modify these based on your folder structure)\n",
        "input_folder = '/content/expression/angry'  # Input folder with images\n",
        "output_folder = '/content/expression/happy1'  # Output folder for happy faces\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Check if CUDA is available and set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load pre-trained face detector model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Load pre-trained emotion detection model\n",
        "# We'll use the facial landmark detector to identify smiles\n",
        "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
        "\n",
        "def has_happy_face(image_path):\n",
        "    \"\"\"Check if there are happy faces in the image\"\"\"\n",
        "\n",
        "    # Read image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Warning: Could not read image {image_path}\")\n",
        "        return False\n",
        "\n",
        "    # Convert to grayscale for detection\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # Check each face for a smile\n",
        "    for (x, y, w, h) in faces:\n",
        "        # Extract face region\n",
        "        face_roi = gray[y:y+h, x:x+w]\n",
        "\n",
        "        # Detect smiles within the face region\n",
        "        smiles = smile_cascade.detectMultiScale(\n",
        "            face_roi,\n",
        "            scaleFactor=1.5,\n",
        "            minNeighbors=15,\n",
        "            minSize=(25, 25)\n",
        "        )\n",
        "\n",
        "        # If smile detected, consider it a happy face\n",
        "        if len(smiles) > 0:\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def process_images():\n",
        "    \"\"\"Process all images in the input folder and move those with happy faces\"\"\"\n",
        "\n",
        "    if not os.path.exists(input_folder):\n",
        "        print(f\"Error: Input folder {input_folder} does not exist\")\n",
        "        return\n",
        "\n",
        "    # Get all image files\n",
        "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "    image_files = [f for f in os.listdir(input_folder)\n",
        "                  if any(f.lower().endswith(ext) for ext in image_extensions)]\n",
        "\n",
        "    print(f\"Found {len(image_files)} images to process\")\n",
        "\n",
        "    moved_images = 0\n",
        "\n",
        "    # Process each image\n",
        "    for img_file in tqdm(image_files):\n",
        "        img_path = os.path.join(input_folder, img_file)\n",
        "\n",
        "        # Check if image contains happy face\n",
        "        if has_happy_face(img_path):\n",
        "            # Move the file to output folder\n",
        "            dest_path = os.path.join(output_folder, img_file)\n",
        "            shutil.move(img_path, dest_path)\n",
        "            moved_images += 1\n",
        "\n",
        "    print(f\"Processed {len(image_files)} images\")\n",
        "    print(f\"Moved {moved_images} images with happy faces to {output_folder}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the face detection process\n",
        "    process_images()\n",
        "    print(\"Processing complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BlxJWXMhM_T",
        "outputId": "42921ccd-15b4-4780-8320-741c426fe919"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Found 8605 images to process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8605/8605 [20:16<00:00,  7.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8605 images\n",
            "Moved 2681 images with happy faces to /content/expression/happy1\n",
            "Processing complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_folders = ['/content/expression/frustration', '/content/expression/exhausted']\n",
        "destination_folder = '/content/expression/angry'\n",
        "\n",
        "for source_folder in source_folders:\n",
        "    for filename in os.listdir(source_folder):\n",
        "        source_path = os.path.join(source_folder, filename)\n",
        "        destination_path = os.path.join(destination_folder, filename)\n",
        "        shutil.move(source_path, destination_path)\n",
        "\n",
        "print(\"Files moved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGlvx7oNDLaF",
        "outputId": "41ce45ea-48c0-4311-fbdf-ff25e179e8e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files moved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define dataset class\n",
        "class ExpressionDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        # Modified to include 3 classes: angry, happy, sad\n",
        "        self.classes = ['angry', 'happy', 'sad']\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        for cls in self.classes:\n",
        "            class_dir = os.path.join(root_dir, cls)\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
        "                    self.images.append(os.path.join(class_dir, img_name))\n",
        "                    self.labels.append(self.class_to_idx[cls])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Enhanced data transforms with more augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load full dataset\n",
        "full_dataset = ExpressionDataset(root_dir='/content/expression/', transform=None)\n",
        "\n",
        "# Split dataset into train, validation, and test sets with better stratification\n",
        "indices = list(range(len(full_dataset)))\n",
        "train_idx, temp_idx = train_test_split(indices, test_size=0.3, stratify=full_dataset.labels, random_state=42)\n",
        "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=[full_dataset.labels[i] for i in temp_idx], random_state=42)\n",
        "\n",
        "# Create subsets with appropriate transforms\n",
        "train_dataset = Subset(ExpressionDataset(root_dir='/content/expression/', transform=train_transforms), train_idx)\n",
        "val_dataset = Subset(ExpressionDataset(root_dir='/content/expression/', transform=val_test_transforms), val_idx)\n",
        "test_dataset = Subset(ExpressionDataset(root_dir='/content/expression/', transform=val_test_transforms), test_idx)\n",
        "\n",
        "# Create data loaders with appropriate batch sizes\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# Define improved model architecture\n",
        "class ExpressionRecognitionModel(nn.Module):\n",
        "    def __init__(self, num_classes=3):  # Updated to 3 classes\n",
        "        super(ExpressionRecognitionModel, self).__init__()\n",
        "        # Load pre-trained ResNet50 instead of VGG16\n",
        "        self.backbone = models.resnet50(weights='IMAGENET1K_V2')\n",
        "\n",
        "        # Freeze early layers\n",
        "        for name, param in self.backbone.named_parameters():\n",
        "            if 'layer4' not in name and 'fc' not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Replace the final fully connected layer\n",
        "        num_ftrs = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        # Custom classifier with dropout and batch normalization\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "        # Attention mechanism for focusing on important facial features\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Conv2d(2048, 512, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 1, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features from the backbone\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.backbone.layer4(x)  # [batch_size, 2048, 7, 7]\n",
        "\n",
        "        # Apply attention mechanism\n",
        "        attention_weights = self.attention(x)\n",
        "        x = x * attention_weights\n",
        "\n",
        "        # Global average pooling\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Apply classifier\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "model = ExpressionRecognitionModel(num_classes=3).to(device)  # Updated to 3 classes\n",
        "\n",
        "# Define loss function with label smoothing for better generalization\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "# Optimizer with decoupled weight decay\n",
        "optimizer = optim.AdamW([\n",
        "    {'params': [p for n, p in model.named_parameters() if 'backbone' in n], 'lr': 1e-5},\n",
        "    {'params': [p for n, p in model.named_parameters() if 'backbone' not in n], 'lr': 1e-4}\n",
        "], weight_decay=1e-2)\n",
        "\n",
        "# Learning rate scheduler with warmup\n",
        "def get_lr_scheduler(optimizer):\n",
        "    lr_scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=[1e-4, 5e-4],\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=40,\n",
        "        pct_start=0.2,  # Warm up for 20% of training\n",
        "        anneal_strategy='cos',\n",
        "        div_factor=25.0,\n",
        "        final_div_factor=1000.0\n",
        "    )\n",
        "    return lr_scheduler\n",
        "\n",
        "scheduler = get_lr_scheduler(optimizer)\n",
        "\n",
        "# Mixed precision training with compatible syntax\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Training and validation functions\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, scheduler, device, scaler):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # Gradient clipping to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # Update learning rate at each step\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
        "\n",
        "# Implementation of mixup augmentation\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "# Training loop - run for all 40 epochs (removed early stopping)\n",
        "num_epochs = 40\n",
        "best_val_acc = 0.0\n",
        "train_losses, val_losses, test_losses = [], [], []\n",
        "train_accs, val_accs, test_accs = [], [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Apply mixup training for every other epoch\n",
        "    use_mixup = (epoch % 2 == 0)\n",
        "\n",
        "    # Training with or without mixup\n",
        "    if use_mixup:\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Apply mixup\n",
        "            inputs, targets_a, targets_b, lam = mixup_data(inputs, labels)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            # Update learning rate\n",
        "            scheduler.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # For accuracy calculation with mixup\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (lam * (predicted == targets_a).sum().item() +\n",
        "                        (1 - lam) * (predicted == targets_b).sum().item())\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100 * correct / total\n",
        "    else:\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion,\n",
        "                                                optimizer, scheduler, device, scaler)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_acc, val_preds, val_labels = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    # Test - added test evaluation for each epoch\n",
        "    test_loss, test_acc, test_preds, test_labels = validate(model, test_loader, criterion, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_accs.append(val_acc)\n",
        "    test_accs.append(test_acc)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')  # Added test accuracy display\n",
        "\n",
        "    # Save best model but don't stop early\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), '/content/best_model.pth')\n",
        "\n",
        "# Load best model and evaluate on test set\n",
        "model.load_state_dict(torch.load('/content/best_model.pth'))\n",
        "test_loss, test_acc, test_preds, test_labels = validate(model, test_loader, criterion, device)\n",
        "print(f'Best Model Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
        "\n",
        "# Plot training metrics\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(train_accs, label='Train Accuracy')\n",
        "plt.plot(val_accs, label='Val Accuracy')\n",
        "plt.plot(test_accs, label='Test Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(test_accs, label='Test Accuracy')\n",
        "plt.title('Test Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/training_metrics.png')\n",
        "\n",
        "# Plot confusion matrix for test set\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Angry', 'Happy', 'Sad'],\n",
        "            yticklabels=['Angry', 'Happy', 'Sad'])\n",
        "plt.title('Confusion Matrix (Test Set)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.savefig('/content/confusion_matrix_test.png')\n",
        "\n",
        "print(f'Best Validation Accuracy: {best_val_acc:.2f}%')\n",
        "print(f'Final Test Accuracy: {test_acc:.2f}%')\n",
        "\n",
        "# Evaluate class-wise performance\n",
        "class_accuracy = {}\n",
        "for i, class_name in enumerate(['Angry', 'Happy', 'Sad']):\n",
        "    class_indices = [j for j, label in enumerate(test_labels) if label == i]\n",
        "    if class_indices:\n",
        "        class_preds = [test_preds[j] for j in class_indices]\n",
        "        class_true = [test_labels[j] for j in class_indices]\n",
        "        acc = accuracy_score(class_true, class_preds) * 100\n",
        "        class_accuracy[class_name] = acc\n",
        "        print(f\"{class_name} Class Accuracy: {acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx7o0aXUxplZ",
        "outputId": "e8bfe32b-6114-441f-c85c-3b14e3ba2a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 94.2MB/s]\n",
            "<ipython-input-8-020e63628b15>:174: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-8-020e63628b15>:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "Train Loss: 0.9961, Train Acc: 55.72%\n",
            "Val Loss: 0.8978, Val Acc: 62.37%\n",
            "Test Loss: 0.9141, Test Acc: 61.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-020e63628b15>:187: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/40\n",
            "Train Loss: 0.9260, Train Acc: 61.60%\n",
            "Val Loss: 0.8707, Val Acc: 64.39%\n",
            "Test Loss: 0.8845, Test Acc: 63.39%\n",
            "Epoch 3/40\n",
            "Train Loss: 0.9290, Train Acc: 61.60%\n",
            "Val Loss: 0.8523, Val Acc: 65.89%\n",
            "Test Loss: 0.8667, Test Acc: 66.27%\n",
            "Epoch 4/40\n",
            "Train Loss: 0.8891, Train Acc: 64.68%\n",
            "Val Loss: 0.8532, Val Acc: 66.06%\n",
            "Test Loss: 0.8703, Test Acc: 66.16%\n",
            "Epoch 5/40\n",
            "Train Loss: 0.9022, Train Acc: 63.55%\n",
            "Val Loss: 0.8470, Val Acc: 66.43%\n",
            "Test Loss: 0.8606, Test Acc: 66.19%\n",
            "Epoch 6/40\n",
            "Train Loss: 0.8622, Train Acc: 66.15%\n",
            "Val Loss: 0.8181, Val Acc: 68.21%\n",
            "Test Loss: 0.8363, Test Acc: 67.32%\n",
            "Epoch 7/40\n",
            "Train Loss: 0.8750, Train Acc: 65.28%\n",
            "Val Loss: 0.8234, Val Acc: 67.62%\n",
            "Test Loss: 0.8342, Test Acc: 67.27%\n",
            "Epoch 8/40\n",
            "Train Loss: 0.8462, Train Acc: 67.27%\n",
            "Val Loss: 0.8110, Val Acc: 68.88%\n",
            "Test Loss: 0.8316, Test Acc: 68.08%\n",
            "Epoch 9/40\n",
            "Train Loss: 0.8747, Train Acc: 65.33%\n",
            "Val Loss: 0.8256, Val Acc: 68.62%\n",
            "Test Loss: 0.8405, Test Acc: 68.48%\n",
            "Epoch 10/40\n",
            "Train Loss: 0.8294, Train Acc: 67.92%\n",
            "Val Loss: 0.8120, Val Acc: 68.94%\n",
            "Test Loss: 0.8301, Test Acc: 68.37%\n",
            "Epoch 11/40\n",
            "Train Loss: 0.8588, Train Acc: 66.30%\n",
            "Val Loss: 0.8227, Val Acc: 68.13%\n",
            "Test Loss: 0.8352, Test Acc: 68.16%\n",
            "Epoch 12/40\n",
            "Train Loss: 0.8155, Train Acc: 68.70%\n",
            "Val Loss: 0.8352, Val Acc: 68.80%\n",
            "Test Loss: 0.8564, Test Acc: 68.00%\n",
            "Epoch 13/40\n",
            "Train Loss: 0.8467, Train Acc: 67.29%\n",
            "Val Loss: 0.8152, Val Acc: 68.27%\n",
            "Test Loss: 0.8305, Test Acc: 67.65%\n",
            "Epoch 14/40\n",
            "Train Loss: 0.8039, Train Acc: 70.05%\n",
            "Val Loss: 0.8213, Val Acc: 69.40%\n",
            "Test Loss: 0.8476, Test Acc: 68.29%\n",
            "Epoch 15/40\n",
            "Train Loss: 0.8394, Train Acc: 67.91%\n",
            "Val Loss: 0.8129, Val Acc: 68.75%\n",
            "Test Loss: 0.8304, Test Acc: 68.43%\n",
            "Epoch 16/40\n",
            "Train Loss: 0.7899, Train Acc: 71.02%\n",
            "Val Loss: 0.8158, Val Acc: 68.56%\n",
            "Test Loss: 0.8335, Test Acc: 68.10%\n",
            "Epoch 17/40\n",
            "Train Loss: 0.8314, Train Acc: 68.33%\n",
            "Val Loss: 0.8227, Val Acc: 68.37%\n",
            "Test Loss: 0.8405, Test Acc: 68.24%\n",
            "Epoch 18/40\n",
            "Train Loss: 0.7737, Train Acc: 71.41%\n",
            "Val Loss: 0.8198, Val Acc: 68.27%\n",
            "Test Loss: 0.8371, Test Acc: 68.35%\n",
            "Epoch 19/40\n",
            "Train Loss: 0.8206, Train Acc: 68.91%\n",
            "Val Loss: 0.8274, Val Acc: 68.67%\n",
            "Test Loss: 0.8456, Test Acc: 68.45%\n",
            "Epoch 20/40\n",
            "Train Loss: 0.7608, Train Acc: 72.44%\n",
            "Val Loss: 0.8358, Val Acc: 68.75%\n",
            "Test Loss: 0.8497, Test Acc: 68.51%\n",
            "Epoch 21/40\n",
            "Train Loss: 0.8089, Train Acc: 69.84%\n",
            "Val Loss: 0.8146, Val Acc: 68.88%\n",
            "Test Loss: 0.8315, Test Acc: 68.67%\n",
            "Epoch 22/40\n",
            "Train Loss: 0.7469, Train Acc: 73.40%\n",
            "Val Loss: 0.8275, Val Acc: 67.86%\n",
            "Test Loss: 0.8372, Test Acc: 68.40%\n",
            "Epoch 23/40\n",
            "Train Loss: 0.7965, Train Acc: 70.39%\n",
            "Val Loss: 0.8176, Val Acc: 68.86%\n",
            "Test Loss: 0.8362, Test Acc: 68.59%\n",
            "Epoch 24/40\n",
            "Train Loss: 0.7375, Train Acc: 74.08%\n",
            "Val Loss: 0.8317, Val Acc: 68.37%\n",
            "Test Loss: 0.8500, Test Acc: 69.02%\n"
          ]
        }
      ]
    }
  ]
}